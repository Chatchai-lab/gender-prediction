{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:23:41.810585Z",
     "start_time": "2026-01-29T00:23:41.806668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:23:43.684278Z",
     "start_time": "2026-01-29T00:23:41.819127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Daten Laden\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "#print(train_data.head())\n",
    "#print(test_data.head())"
   ],
   "id": "d9439119db787b88",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:23:54.668051Z",
     "start_time": "2026-01-29T00:23:43.694210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#X und Y aus train\n",
    "\n",
    "print(\"Rohdaten\")\n",
    "print(\"Train Zeilen (Pageviews):\", train_data.shape[0])\n",
    "print(\"Test Zeilen (Pageviews):\", test_data.shape[0])\n",
    "print(\"Unterschiedliche Paths im Train (roh):\",\n",
    "      train_data[\"path\"].nunique())\n",
    "print(\"Unterschiedliche Paths im Test (roh):\",\n",
    "      test_data[\"path\"].nunique())\n",
    "\n",
    "#Alle Paths pro User zusammenfassen\n",
    "train_docs = train_data.groupby(\"user_id\")[\"path\"].apply(lambda x: \" \".join(x))\n",
    "test_docs = test_data.groupby(\"user_id\")[\"path\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"nach Aggregation\")\n",
    "print(\"Train Docs (1 Zeile pro User):\", train_docs.shape[0])\n",
    "print(\"Test Docs (1 Zeile pro User):\", test_docs.shape[0])\n",
    "\n",
    "vec = CountVectorizer(min_df=5)\n",
    "\n",
    "#Eingabevariable\n",
    "X = vec.fit_transform(train_docs)\n",
    "X_test = vec.transform(test_docs)\n",
    "print(\"Paths als Features nach min_df=5:\",\n",
    "      len(vec.get_feature_names_out()))\n",
    "\n",
    "\n",
    "\n",
    "#Zielvariable\n",
    "y = train_data.groupby(\"user_id\")[\"gender\"].first()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "296293fa0c98dba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohdaten\n",
      "Train Zeilen (Pageviews): 2403279\n",
      "Test Zeilen (Pageviews): 275840\n",
      "Unterschiedliche Paths im Train (roh): 26394\n",
      "Unterschiedliche Paths im Test (roh): 26392\n",
      "-------------------------\n",
      "nach Aggregation\n",
      "Train Docs (1 Zeile pro User): 13513\n",
      "Test Docs (1 Zeile pro User): 1487\n",
      "Paths als Features nach min_df=5: 86101\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:23:58.295400Z",
     "start_time": "2026-01-29T00:23:54.677688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Feature Engineering\n",
    "\n",
    "\n",
    "#Train\n",
    "\n",
    "# manche User besuchen eine Seite öfter -> evlt. Kaufabsicht, andere Weniger vllt. auf der Website verirrt\n",
    "total_visits = train_data.groupby(\"user_id\").size()\n",
    "\n",
    "# viele unique paths -> stöbern, wenige unique paths -> gezielte Kaufabsicht z.B. Schuhe\n",
    "unique_paths = train_data.groupby(\"user_id\")[\"path\"].nunique()\n",
    "\n",
    "# wie oft kommt der User zurück Pause > 30min\n",
    "train_data[\"timestamp\"] = pd.to_datetime(train_data[\"timestamp\"], errors=\"coerce\")\n",
    "train_sorted = train_data.sort_values([\"user_id\", \"timestamp\"])\n",
    "train_sorted[\"diff\"] = train_sorted.groupby(\"user_id\")[\"timestamp\"].diff()\n",
    "train_sorted[\"new_session\"] = train_sorted[\"diff\"] > pd.Timedelta(minutes=30)\n",
    "num_sessions = train_sorted.groupby(\"user_id\")[\"new_session\"].sum()\n",
    "\n",
    "# Reihenfolge an train_docs Index anpassen\n",
    "total_visits = total_visits.reindex(train_docs.index, fill_value=0)\n",
    "unique_paths = unique_paths.reindex(train_docs.index, fill_value=0)\n",
    "num_sessions = num_sessions.reindex(train_docs.index, fill_value=0)\n",
    "\n",
    "# Extra Feature Matrix TRAIN (n_users, 3)\n",
    "X_extra = np.vstack([\n",
    "    total_visits.values,\n",
    "    unique_paths.values,\n",
    "    num_sessions.values\n",
    "]).T\n",
    "\n",
    "# An X anhängen\n",
    "X = hstack([X, csr_matrix(X_extra)]).tocsr()\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Test\n",
    "\n",
    "total_visits_test = test_data.groupby(\"user_id\").size()\n",
    "unique_paths_test = test_data.groupby(\"user_id\")[\"path\"].nunique()\n",
    "\n",
    "test_data[\"timestamp\"] = pd.to_datetime(test_data[\"timestamp\"], errors=\"coerce\")\n",
    "test_sorted = test_data.sort_values([\"user_id\", \"timestamp\"])\n",
    "\n",
    "test_sorted[\"diff\"] = test_sorted.groupby(\"user_id\")[\"timestamp\"].diff()\n",
    "test_sorted[\"new_session\"] = test_sorted[\"diff\"] > pd.Timedelta(minutes=30)\n",
    "\n",
    "num_sessions_test = test_sorted.groupby(\"user_id\")[\"new_session\"].sum()\n",
    "\n",
    "# Reihenfolge an test_docs Index anpassen\n",
    "total_visits_test = total_visits_test.reindex(test_docs.index, fill_value=0)\n",
    "unique_paths_test = unique_paths_test.reindex(test_docs.index, fill_value=0)\n",
    "num_sessions_test = num_sessions_test.reindex(test_docs.index, fill_value=0)\n",
    "\n",
    "# Extra Feature Matrix TEST (n_users_test, 3)\n",
    "X_test_extra = np.vstack([\n",
    "    total_visits_test.values,\n",
    "    unique_paths_test.values,\n",
    "    num_sessions_test.values\n",
    "]).T\n",
    "\n",
    "# An X_test anhängen\n",
    "X_test = hstack([X_test, csr_matrix(X_test_extra)]).tocsr()\n",
    "\n",
    "\n",
    "# ---------- Check ----------\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ],
   "id": "ac0b8576af7d2107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (13513, 86104)\n",
      "X_test shape: (1487, 86104)\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:24:19.836306Z",
     "start_time": "2026-01-29T00:23:58.303389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Validierung\n",
    "#Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "#Modell definieren\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "#CV\n",
    "cv_scores = cross_val_score(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "print(\"durchschn. CV Genauigkeit (Training):\", cv_scores.mean())\n"
   ],
   "id": "73c5dc6ccfb084eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "durchschn. CV Genauigkeit (Training): 0.9957446808510639\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:24:25.917729Z",
     "start_time": "2026-01-29T00:24:19.851612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict(X_val)\n",
    "print(\"Interne Validations Genauigkeit (Testing):\", accuracy_score(y_val, val_pred))"
   ],
   "id": "a4690347f7f7bdf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interne Validations Genauigkeit (Testing): 0.9959304476507584\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:24:32.489316Z",
     "start_time": "2026-01-29T00:24:25.935206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Finales Training auf allen Trainingsdaten\n",
    "model.fit(X, y)\n",
    "print(\"model expects:\", model.n_features_in_)\n",
    "print(X.shape, X_test.shape, model.n_features_in_)"
   ],
   "id": "4a310e5e2e83297d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model expects: 86104\n",
      "(13513, 86104) (1487, 86104) 86104\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:24:32.524687Z",
     "start_time": "2026-01-29T00:24:32.506285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Vorhersage auf test.csv (ohne Labels)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predictions für test.csv erstellt\")"
   ],
   "id": "3f9c9f6edc473fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions für test.csv erstellt\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:24:32.546559Z",
     "start_time": "2026-01-29T00:24:32.535946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Speichern\n",
    "\n",
    "output = pd.DataFrame({\n",
    "    \"user_id\": test_docs.index,\n",
    "    \"gender\": predictions\n",
    "})\n",
    "\n",
    "output.to_csv(\"./data/predictions.csv\", index=False)\n",
    "print(\"Vorhersage gespeichert als predictions.csv\")"
   ],
   "id": "e82398c7105a48c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage gespeichert als predictions.csv\n"
     ]
    }
   ],
   "execution_count": 142
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
